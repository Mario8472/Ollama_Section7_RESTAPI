import requests
import json

url = "http://localhost:11434/api/generate"

# dictionary 
data = {
    "model": "llama3.2:latest",
    "prompt": "Tell me a short story and make it funny"
}

response = requests.post(url, json = data, stream = True)

# check the response status
if response.status_code == 200: 
    print("Generated text: ", end=" ", flush=True) # end=" " prevents a newline. flush=True forces immediate output (important for streaming)
    # iterate over the streaming response
    for line in response.iter_lines():  # Streaming servers often send one JSON object per line. Reads the HTTP response line by line. Each line is a byte string. Each line represents one chunk of generated output
        if line:    # Filters out keep-alive or blank lines
            # Decode the line and parse the JSON
            decoded_line = line.decode("utf-8")
            result = json.loads(decoded_line)   # Converts the JSON string into a Python dictionary
            # Get the text from the response
            generated_text = result.get("response", "") # Safely retrieves the "response" field. If missing, returns an empty string instead of crashing. This is the actual text generated by the model.
            print(generated_text, end=" ", flush=True)
else:
    print("Error: ", response.status_code, response.text)
